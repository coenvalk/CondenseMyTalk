{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the incredible amount of information being added to the internet every minute, it is humanly impossible to sift through all this data to find meaningful content for me to stay informed about everything that I want to. Additionally, with class and lectures put online, I personally have even more difficulty staying focused on the class material. I often notice myself switching the playback speed to 1.5 or 2 times for a while to have the pace of the slow parts feel good, but after a few moments I realize that I missed something important, need to rewind, and play what I already listened to at normal speed to understand all of the concepts portrayed in the video! Especially in review times before a test, I always have trouble sifting through hours worth of footage to find the example or content I was looking for.\n",
    "\n",
    "## Background\n",
    "\n",
    "In the Spring semester of 2019, I participated in a hackathon hosted by my school where I got this idea and worked on it a little bit. My idea was to give some importance value to each moment in the video, creating a sort of \"importance curve\". The \"total importance\" of the video could then be described as the area under the curve of this importance function. The toy example below can show spikes and valleys of importance, and the orange area resembles the most important moments of the video, and thus are the moments selected in the summarization.\n",
    "\n",
    "It was a fun project to work on and I learned a lot from it! I thought while I'm practicing social distancing I might as well revisit this project and learn more about established video summarization techniques out there today.\n",
    "\n",
    "## Available Free Videos\n",
    "\n",
    "There is plenty of content online we can use for this. I'm going to be taking some of these [public test videos](https://gist.github.com/jsturgis/3b19447b304616f18657)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import transform\n",
    "from IPython.display import Video\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics, cluster, decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"../data/\"\n",
    "url_root = \"https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Big Buck Bunny',\n",
       " 'Elephant Dream',\n",
       " 'For Bigger Blazes',\n",
       " 'For Bigger Escape',\n",
       " 'For Bigger Fun',\n",
       " 'For Bigger Joyrides',\n",
       " 'For Bigger Meltdowns',\n",
       " 'Sintel',\n",
       " 'Subaru Outback On Street And Dirt',\n",
       " 'Tears of Steel',\n",
       " 'Volkswagen GTI Review',\n",
       " 'We Are Going On Bullrun',\n",
       " 'What care can you get for a grand?']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(data_root, \"videos.json\"), 'r') as f:\n",
    "    videos = json.load(f)\n",
    "[v['title'] for v in videos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4\" controls  width=\"400\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid_url = url_root + videos[0]['sources'][0]\n",
    "Video(vid_url, width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 41.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cap = cv2.VideoCapture(vid_url)\n",
    "frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frameWidth = 128 # int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frameHeight = int(frameWidth * (cap.get(cv2.CAP_PROP_FRAME_HEIGHT) / cap.get(cv2.CAP_PROP_FRAME_WIDTH))) + 1\n",
    "V = np.zeros((frameCount, frameHeight, frameWidth), np.dtype('uint8'))\n",
    "f = 0\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        frame_resized = cv2.resize(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), (frameWidth, frameHeight), interpolation=cv2.INTER_CUBIC)\n",
    "        V[f] = frame_resized\n",
    "        f += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization Techniques\n",
    "\n",
    "I read this [survey](SURVEY) on automatic video summarization and used the referenced papers explaining the algorithms in more detail to implement the following summarization techniques\n",
    "\n",
    "- VSCAN\n",
    "- VSUMM\n",
    "- STILL and MOVING (STIMO)\n",
    "- Delauney Triangulation (DT)\n",
    "- Video Summarization Using Higher Order Color Moments (VSUHCM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. <a id=\"VSUHCM\" href=\"https://github.com/coenvalk/CondenseMyTalk/blob/master/literature/VSUHCM.pdf\">Jadhav, Mrs. Poonam S., and Dipti S. Jadhav. “Video Summarization Using Higher Order Color Moments (VSUHCM).” Procedia Computer Science, vol. 45, 2015, pp. 275–281., doi:10.1016/j.procs.2015.03.140.</a>\n",
    "1. <a id=\"VSCAN\" href=\"https://github.com/coenvalk/CondenseMyTalk/blob/master/literature/VSCAN.pdf\">Karim M. Mohamed, Mohamed A. Ismail, and Nagia M. Ghanem (2014) VSCAN: An Enhanced Video Summarization using Density-based Spatial Clustering. Computer and Systems Engineering Department Faculty of Engineering, Alexandria University Alexandria, Egypt.</a>\n",
    "1. <a id=\"STIMO\" href=\"https://github.com/coenvalk/CondenseMyTalk/blob/master/literature/STIMO.pdf\">Marco, Geraci and Montenegro, (2010)’ STIMO: Still and Moving video storyboard for the Web Scenario’ Journal Multimedia Tools and Applications, Volumes =46, issue1,January 2010,pages 47-69.</a>\n",
    "1. <a id=\"DT\" href=\"https://github.com/coenvalk/CondenseMyTalk/blob/master/literature/DT.pdf\">Padmavathi Mundur, Yong Rao, Yelena Yesha,(2006)‘Key frame-based video summarization using Delaunay clustering’ International Journal on Digital Libraries April 2006, Volume 6, Issue 2, pp 219-232.</a>\n",
    "1. <a id=\"VSUMM\" href=\"https://github.com/coenvalk/CondenseMyTalk/blob/master/literature/VSUMM.pdf\">Sandra E. F. de Avila, Antonio da Luz Jr., Arnaldo de A. Araujo, and Matthieu Cord, (2008). `VSUMM: An Approach for Automatic Video Summarization and Quantitative Evaluation', XXI Brazilian Symposium on Computer Graphics and Image Processing IEEE.</a>\n",
    "1. <a id=\"SURVEY\" href=\"https://github.com/coenvalk/CondenseMyTalk/blob/master/literature/SURVEY.pdf\">Sebastian, Tinumol, and Jiby J. “A Survey on Video Summarization Techniques.” International Journal of Computer Applications, vol. 132, no. 13, 2015, pp. 30–32., doi:10.5120/ijca2015907592.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
